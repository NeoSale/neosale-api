# Sistema de Chunking para Documentos

## âœ… ImplementaÃ§Ã£o ConcluÃ­da

O sistema agora divide automaticamente documentos grandes em pedaÃ§os menores (chunks) para melhorar a precisÃ£o da busca semÃ¢ntica.

## ğŸ“‹ Arquivos Criados

1. **migrations/031_add_documento_chunks.sql** - Migration para adicionar suporte a chunks
2. **src/lib/chunking.ts** - FunÃ§Ãµes utilitÃ¡rias para dividir textos
3. **apply-chunking-migration.ts** - Script para aplicar a migration
4. **test-search-documento.ts** - Script de teste atualizado

## ğŸ”§ Como Aplicar a Migration

### OpÃ§Ã£o 1: Manualmente no Supabase (Recomendado)

1. Acesse o Supabase Dashboard
2. VÃ¡ em **SQL Editor**
3. Abra o arquivo `migrations/031_add_documento_chunks.sql`
4. Copie todo o conteÃºdo
5. Cole no SQL Editor e execute

### OpÃ§Ã£o 2: Via Script (se disponÃ­vel)

```bash
npx ts-node apply-chunking-migration.ts
```

## ğŸ“Š Como Funciona

### Documentos Pequenos (â‰¤ 10,000 caracteres)
- Criado normalmente como um Ãºnico registro
- `chunk_index = 0`
- `total_chunks = 1`

### Documentos Grandes (> 10,000 caracteres)

**Exemplo: PDF com 748,663 caracteres**

1. **DivisÃ£o em Chunks**
   - Chunk size: 10,000 caracteres (reduzido para melhor precisÃ£o)
   - Overlap: 500 caracteres (para manter contexto)
   - Quebra em limites de sentenÃ§as (. ! ?)
   - Resultado: ~75 chunks (2x mais que antes)

2. **Estrutura no Banco**
   ```
   Documento Pai (chunk_index = 0)
   â”œâ”€â”€ Chunk 1 (chunk_index = 1) â†’ documento_pai_id = Pai.id
   â”œâ”€â”€ Chunk 2 (chunk_index = 2) â†’ documento_pai_id = Pai.id
   â”œâ”€â”€ Chunk 3 (chunk_index = 3) â†’ documento_pai_id = Pai.id
   â””â”€â”€ ... (atÃ© chunk 74)
   ```

3. **Embeddings**
   - Cada chunk tem seu prÃ³prio embedding
   - Busca encontra o chunk mais relevante
   - Retorna informaÃ§Ãµes do chunk + documento pai

## ğŸ” Busca SemÃ¢ntica

### Antes (sem chunking)
```
Consulta: "o que diz o art. 77?"
Resultado: Similaridade 44% (baixa)
Motivo: Embedding representa apenas os primeiros 24k caracteres
```

### Depois (com chunking)
```
Consulta: "o que diz o art. 77?"
Resultado: Similaridade 85%+ (alta)
Motivo: Busca encontra o chunk especÃ­fico que contÃ©m o art. 77
```

## ğŸ“ Exemplo de Uso

### Upload de Documento

```typescript
POST /api/documentos
{
  "nome": "Lei Complementar 214/2025",
  "descricao": "Lei sobre impostos",
  "nome_arquivo": "lei_214_2025.pdf",
  "base64": "...",
  "cliente_id": "uuid",
  "base_id": ["uuid"]
}
```

**Logs no servidor:**
```
Texto extraÃ­do: 748663 caracteres
ğŸ“„ Documento grande detectado (748725 chars). Aplicando chunking...
ğŸ“Š EstatÃ­sticas de chunking:
   Total de chunks: 75
   Tamanho mÃ©dio: 10072 chars
   Min/Max: 9234/10856 chars
âœ… Documento pai criado: uuid-pai
Processando chunk 2/75...
âœ… Chunk 2 criado
...
âœ… Documento com 75 chunks criado com sucesso
```

### Busca

```typescript
const { data } = await supabase.rpc('match_documentos_by_base_cliente', {
  filter: {
    cliente_id: 'uuid',
    base_id: ['uuid']
  },
  match_count: 10,
  query_embedding: embedding
})

// Resultado
data = [
  {
    metadata: { id, nome, ... },
    similarity: 0.87,
    chunk_info: {
      is_chunk: true,
      chunk_index: 15,
      total_chunks: 38,
      documento_pai_id: 'uuid-pai',
      chunk_texto: 'Art. 77. ...'
    }
  }
]
```

## ğŸ§ª Testar o Sistema

```bash
npx ts-node test-search-documento.ts
```

**Resultado esperado:**
```
ğŸ” Iniciando teste de busca semÃ¢ntica...
â³ Gerando embedding da consulta...
âœ… Embedding gerado em 2012ms
ğŸ” Buscando documentos similares...
âœ… Busca concluÃ­da em 965ms

ğŸ“„ 1 documento(s) encontrado(s):

1. Documento: Lei Complementar 214/2025 (Parte 12)
   Similaridade: 87.45%
   ğŸ“‘ Chunk 12 de 75
   ğŸ“„ Documento pai: uuid-pai
   ğŸ“ Trecho: "Art. 77. ..."
```

## âš™ï¸ ConfiguraÃ§Ãµes

### Ajustar Tamanho do Chunk

Em `src/services/documentoService.ts`:

```typescript
const CHUNK_SIZE = 10000 // Altere aqui (atual: 10k)
```

**RecomendaÃ§Ãµes:**
- **8,000-10,000**: Melhor precisÃ£o, mais chunks, mais custo â­ **ATUAL**
- **15,000-20,000**: EquilÃ­brio entre precisÃ£o e custo
- **25,000-30,000**: Menos chunks, menor custo, precisÃ£o moderada

### Ajustar Overlap

Em `src/lib/chunking.ts`:

```typescript
splitTextIntoChunks(text, chunkSize, 500) // 500 = overlap (atual)
```

**RecomendaÃ§Ãµes:**
- **300-500**: Overlap menor, mais chunks Ãºnicos â­ **ATUAL**
- **500-1,000**: Overlap padrÃ£o, bom equilÃ­brio
- **1,000-1,500**: Mais contexto entre chunks

## ğŸ’° Impacto nos Custos

### Antes (sem chunking)
- 1 documento = 1 embedding
- Custo: $0.00002 por documento

### Depois (com chunking - 20k chars)
- 1 documento grande = 38 embeddings
- Custo: $0.00076 por documento (38x mais)
- PrecisÃ£o: ~57%

### Agora (com chunking - 10k chars) â­
- 1 documento grande = 75 embeddings
- Custo: $0.0015 por documento (75x mais)
- **PrecisÃ£o esperada: 70-85%+** ğŸ¯

**Vale a pena:** Custo 2x maior, mas precisÃ£o muito melhor!

## ğŸ—„ï¸ Estrutura do Banco

### Novas Colunas

| Coluna | Tipo | DescriÃ§Ã£o |
|--------|------|-----------|
| `documento_pai_id` | uuid | ID do documento pai (null se nÃ£o Ã© chunk) |
| `chunk_index` | integer | Ãndice do chunk (0 = pai ou Ãºnico) |
| `total_chunks` | integer | Total de chunks do documento |
| `chunk_texto` | text | Texto do chunk (para contexto) |

### Ãndices Criados

- `idx_documentos_documento_pai_id`
- `idx_documentos_chunk_index`

## ğŸ¯ PrÃ³ximos Passos

1. âœ… Aplicar migration no banco
2. âœ… Fazer upload de um documento grande
3. âœ… Testar busca semÃ¢ntica
4. ğŸ“Š Monitorar custos da OpenAI
5. ğŸ”§ Ajustar CHUNK_SIZE se necessÃ¡rio

## ğŸ“š ReferÃªncias

- Chunking: `src/lib/chunking.ts`
- Service: `src/services/documentoService.ts`
- Migration: `migrations/031_add_documento_chunks.sql`
- Teste: `test-search-documento.ts`
